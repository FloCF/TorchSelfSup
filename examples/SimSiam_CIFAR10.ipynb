{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd933ab8",
   "metadata": {},
   "source": [
    "# [SimSiam](https://arxiv.org/abs/2011.10566) on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4920ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from models import SimSiam\n",
    "from trainer import SSL_Trainer\n",
    "from utils import SSL_CIFAR10\n",
    "\n",
    "# Define hyperparameters\n",
    "data_root = './data/'\n",
    "save_root = './results/simsiam/'\n",
    "\n",
    "dl_kwargs = {'batch_size': 512, 'shuffle': True, 'num_workers': 2}\n",
    "\n",
    "# Define data\n",
    "ssl_data = SSL_CIFAR10(data_root,'SimSiam', dl_kwargs)\n",
    "\n",
    "# general training params\n",
    "train_params = {'save_root': save_root, 'num_epochs': 800, 'optimizer': SGD,\n",
    "                'scheduler': CosineAnnealingLR, 'warmup_epochs': 10, 'iter_scheduler':True,\n",
    "                'evaluate_at': [1,50,100,200,400,600], 'verbose':True}\n",
    "\n",
    "# params of optimizer\n",
    "# From original paper\n",
    "optim_params = {'lr':0.03 * dl_kwargs['batch_size']/256,\n",
    "                'weight_decay': 5e-4,\n",
    "                'momentum' : 0.9}\n",
    "\n",
    "# params of scheduler\n",
    "scheduler_params = {'T_max': (train_params['num_epochs']-train_params['warmup_epochs'])*len(ssl_data.train_dl)}\n",
    "                    # 'eta_min':1e-4} in orginal implementation\n",
    "\n",
    "# Set parameters for fitting linear protocoler\n",
    "eval_params  = {'lr':1e-2, 'num_epochs': 25, 'milestones': [12,20]}\n",
    "\n",
    "# Get device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Print Device Type\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Program running on {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"Program running on CPU\")\n",
    "    \n",
    "# Create folder if it does not exists\n",
    "makedirs(save_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7fa78",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "resnet = resnet18(zero_init_residual=True)\n",
    "# Cifar specifics\n",
    "resnet.conv1 = torch.nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "resnet.maxpool = torch.nn.Identity()\n",
    "\n",
    "model = SimSiam(resnet,\n",
    "                projector_hidden = (2048, 2048, 2048),\n",
    "                predictor_hidden = (512, 2048))\n",
    "\n",
    "# Define Trainer\n",
    "cifar10_trainer = SSL_Trainer(model, ssl_data, device)\n",
    "\n",
    "# Train\n",
    "cifar10_trainer.train(**train_params, optim_params=optim_params,\n",
    "                      scheduler_params=scheduler_params, eval_params=eval_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4ba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
