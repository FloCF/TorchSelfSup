{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd933ab8",
   "metadata": {},
   "source": [
    "# Trying Bootstrap Your Own Latent (BYOL) on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c5bf3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program running on CPU\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "from os import listdir, makedirs, path\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Print Device Type\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Program running on {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"Program running on CPU\")\n",
    "\n",
    "# Define hyperparameters\n",
    "data_root = '/home/fcfschulz/Documents/workspace/data/Vision/torchvision_ds/'\n",
    "save_root = '/home/fcfschulz/Documents/workspace/data/saved_models/byol_cifar10/'\n",
    "\n",
    "### For COLAB ############################################################\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#\n",
    "#data_root = './'\n",
    "#save_root ='./drive/MyDrive/Colab_Notebooks/PhD/data/saved_models/byol/'\n",
    "##########################################################################\n",
    "\n",
    "# Make save root\n",
    "makedirs(save_root, exist_ok=True)\n",
    "\n",
    "dl_kwargs = {'batch_size': 256, 'shuffle': True, 'num_workers': 2}\n",
    "\n",
    "train_params = {'base_lr':0.2, 'num_epochs': 250, 'warmup_epchs': 10,\n",
    "                'weight_decay': 1.5e-6, 'eta_min':1e-6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7fa78",
   "metadata": {},
   "source": [
    "# BYOL\n",
    "### Define Augmentation and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e82d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from augmentation import BYOL_transform\n",
    "\n",
    "train_ds = CIFAR10(root=data_root, train = True, download = True,\n",
    "                   transform = BYOL_transform(image_size=32, normalize=(0.5,0.5)))\n",
    "\n",
    "train_dl = DataLoader(train_ds, drop_last=True, **dl_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceae48d",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fee883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BYOL\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "backbone_net = resnet18()\n",
    "repre_dim = backbone_net.fc.in_features\n",
    "backbone_net.fc = nn.Flatten()\n",
    "\n",
    "byol = BYOL(backbone_net, repre_dim, 32, 1024).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2858b2",
   "metadata": {},
   "source": [
    "### Define Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = opt.Adam(byol.parameters(),\n",
    "                     lr = train_params['base_lr'],\n",
    "                     weight_decay = train_params['weight_decay'])\n",
    "\n",
    "# Define scheduler for warmup\n",
    "scheduler = opt.lr_scheduler.LambdaLR(optimizer, lambda it : (it+1)/(train_params['warmup_epchs']*len(train_dl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b717a2",
   "metadata": {},
   "source": [
    "### Check for trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 0\n",
    "loss_hist = []\n",
    "lr_hist = []\n",
    "tau_hist = []\n",
    "\n",
    "if path.exists(path.join(save_root, f'epoch_{5:03}.tar')):\n",
    "    user_answer = \"Users_answer\"\n",
    "    while user_answer not in [\"y\",\"n\"]:\n",
    "        user_answer = input(\"Pretrained model available, use it?[y/n]: \").lower()[0]\n",
    "    if user_answer==\"y\":\n",
    "        epoch_start = max([int(file[-7:-4]) for file in listdir(save_root)])\n",
    "        # Load data\n",
    "        saved_data = torch.load(path.join(save_root, f'epoch_{epoch_start:03}.tar'), map_location=device)\n",
    "        # Extract data\n",
    "        byol.load_state_dict(saved_data['model'])\n",
    "        optimizer.load_state_dict(saved_data['optim'])\n",
    "        if epoch_start >= train_params['warmup_epchs']:\n",
    "            iters_left = (train_params['num_epochs']-train_params['warmup_epchs'])*len(train_dl)\n",
    "            scheduler = opt.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                       iters_left,\n",
    "                                                       eta_min=train_params['eta_min'])\n",
    "        scheduler.load_state_dict(saved_data['sched'])\n",
    "        loss_hist = saved_data['loss_hist']\n",
    "        lr_hist = saved_data['lr_hist']\n",
    "        tau_hist = saved_data['tau_hist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd25bc1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iters = train_params['num_epochs'] * len(train_dl)\n",
    "\n",
    "for epoch in range(epoch_start, train_params['num_epochs']):\n",
    "    i = 0\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "    for (x1,x2), _ in train_dl:\n",
    "        x1,x2 = x1.to(device), x2.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        loss = byol(x1,x2)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update momentum encoder\n",
    "        τ = byol.get_tau(1+i+len(train_dl)*epoch,total_iters)\n",
    "        byol.update_moving_average(τ)\n",
    "        tau_hist.append(τ)\n",
    "        i += 1\n",
    "        \n",
    "        # Scheduler every iteration for cosine deday\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save loss and LR\n",
    "        epoch_loss += loss.item()\n",
    "        lr_hist.extend(scheduler.get_last_lr())\n",
    "    \n",
    "    # Switch to Cosine Decay after warmup period\n",
    "    if epoch+1==train_params['warmup_epchs']:\n",
    "        iters_left = (train_params['num_epochs']-train_params['warmup_epchs'])*len(train_dl)\n",
    "        scheduler = opt.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                       iters_left,\n",
    "                                                       eta_min=train_params['eta_min'])\n",
    "    \n",
    "    # Log\n",
    "    loss_hist.append(epoch_loss/len(train_dl))\n",
    "    print(f'Epoch: {epoch}, Loss: {loss_hist[-1]}, Time epoch: {time.time() - start_time}')\n",
    "    \n",
    "    # Save stats\n",
    "    if (epoch+1)%5==0:\n",
    "        torch.save({'model':byol.state_dict(),\n",
    "                    'optim': optimizer.state_dict(),\n",
    "                    'sched': scheduler.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'lr_hist': lr_hist,\n",
    "                    'tau_hist': tau_hist}, \n",
    "                   path.join(save_root, f'epoch_{epoch+1:03}.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f8461",
   "metadata": {},
   "source": [
    "### Visualize loss, learning rate and $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n",
    "ax1.plot(loss_hist)\n",
    "ax1.set_title(\"Loss\")\n",
    "\n",
    "ax2.plot(lr_hist)\n",
    "ax2.set_title(\"Learning rate\")\n",
    "\n",
    "ax3.plot(tau_hist)\n",
    "ax3.set_title(\"Tau\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14cf40",
   "metadata": {},
   "source": [
    "### Colab transfer saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#!cp ./saved/* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552ef10",
   "metadata": {},
   "source": [
    "# Linear Evaluation Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a40b8e",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, (0.6, 1.),interpolation=transforms.InterpolationMode('bicubic')),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0.5,0.5)])\n",
    "test_transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "le_train_ds  = CIFAR10(root=data_root, train = True, transform = train_transf, download = True)\n",
    "test_ds  = CIFAR10(root=data_root, train = False, transform = test_transf, download = True)\n",
    "\n",
    "le_train_dl = DataLoader(le_train_ds, drop_last=True, **dl_kwargs)\n",
    "test_dl  = DataLoader(test_ds, drop_last=False, **dl_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7fcb4",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3871be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_byol(byol_net):\n",
    "    # Define encoder\n",
    "    classifier = copy.deepcopy(byol_net.encoder_online)\n",
    "    \n",
    "    for p in classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "    classifier[1] = nn.Sequential(nn.Linear(512,10))\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "\n",
    "def train_model(dataloader, model, optim, sched, num_epochs, criterion, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        for x,y in dataloader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            # forward\n",
    "            loss = criterion(model(x), y)\n",
    "            # backward\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        # scheduler step\n",
    "        sched.step()\n",
    "            \n",
    "\n",
    "def get_accuracy(datalaoder, model, device = 'cpu'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for x, y in datalaoder:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(x)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_params = {'base_lr':1e-2, 'num_epochs': 20, 'schedule_step': 8}\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# random init baseline\n",
    "byol = BYOL(backbone_net, repre_dim, 32, 1024).to(device)\n",
    "# Define encoder\n",
    "classifier = extract_from_byol(byol).to(device)\n",
    "# Define optimizer\n",
    "le_optimizer = opt.Adam(classifier.parameters(), eval_params['base_lr'])\n",
    "# Define scheduler\n",
    "le_scheduler = opt.lr_scheduler.StepLR(le_optimizer, eval_params['schedule_step'])\n",
    "# Train model\n",
    "train_model(le_train_dl, classifier, le_optimizer, le_scheduler,\n",
    "            eval_params['num_epochs'], ce_loss, device)\n",
    "    \n",
    "# Check accuracy\n",
    "print(f'Accuracy of random init: {get_accuracy(test_dl, classifier, device)}')\n",
    "\n",
    "# Check other models\n",
    "models_avail = [f for f in listdir(save_root) if path.isfile(path.join(save_root, f))]\n",
    "models_avail.sort()\n",
    "\n",
    "for model_name in models_avail:\n",
    "    # Load model\n",
    "    saved_data = torch.load(path.join(save_root, model_name), map_location=device)\n",
    "    # extract weights\n",
    "    byol.load_state_dict(saved_data['model'])\n",
    "    \n",
    "    # Define encoder\n",
    "    classifier = extract_from_byol(byol).to(device)\n",
    "    # Define optimizer\n",
    "    le_optimizer = opt.Adam(classifier.parameters(), eval_params['base_lr'])\n",
    "    # Define scheduler\n",
    "    le_scheduler = opt.lr_scheduler.StepLR(le_optimizer, eval_params['schedule_step'])\n",
    "    \n",
    "    # Train model\n",
    "    train_model(le_train_dl, classifier, le_optimizer, le_scheduler,\n",
    "                eval_params['num_epochs'], ce_loss, device)\n",
    "    \n",
    "    # Check accuracy\n",
    "    print(f'Accuracy of model {model_name}: {get_accuracy(test_dl, classifier, device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741c57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4ba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Playground)",
   "language": "python",
   "name": "playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
